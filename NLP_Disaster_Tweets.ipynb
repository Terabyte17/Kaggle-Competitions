{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Disaster Tweets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d0Nv5FVyB4r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87978d0b-f5bb-498e-be7c-e93734337f36"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5MHmonSxz2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import gc\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import gensim\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from collections import defaultdict, Counter\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tqdm import tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Bidirectional\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNxsetXIx9bL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir = '/content/drive/My Drive'\n",
        "train = pd.read_csv(os.path.join(dir, 'train (3).csv'))\n",
        "test = pd.read_csv(os.path.join(dir, 'test (3).csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQDHLiM_yR4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_url(text):\n",
        "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url.sub(r\" \",text)\n",
        "train['text']=train['text'].apply(lambda x:remove_url(x))\n",
        "test['text']=test['text'].apply(lambda x:remove_url(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T-AqWARy5rf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_htmltags(text):\n",
        "    html_tag = re.compile(r'<.*?>')\n",
        "    return html_tag.sub(r' ',text)\n",
        "train['text']=train['text'].apply(lambda x:remove_htmltags(x))\n",
        "test['text']=test['text'].apply(lambda x:remove_htmltags(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2OkpejXzEeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  \n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  \n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  \n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "train['text']=train['text'].apply(lambda x:remove_emoji(x))\n",
        "test['text']=test['text'].apply(lambda x:remove_emoji(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucUjPxDbzQ2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punctuation(text):\n",
        "    trans_table = str.maketrans('','',string.punctuation)\n",
        "    return text.translate(trans_table)\n",
        "train['text']=train['text'].apply(lambda x:remove_punctuation(x))\n",
        "test['text']=test['text'].apply(lambda x:remove_punctuation(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFbwbkrYzkb7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "345541fa-f675-4c4c-f74d-f7d01880f52d"
      },
      "source": [
        "!pip install pyspellchecker"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.6/dist-packages (0.5.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7gPn0tUzqU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spellchecker import SpellChecker\n",
        "spell = SpellChecker()\n",
        "def correct_spellings(text):\n",
        "  print('ho raha')\n",
        "  corrected_text=[]\n",
        "  misspelled_words = spell.unknown(text.split())\n",
        "  for word in text.split():\n",
        "    if word in misspelled_words:\n",
        "      corrected_text.append(spell.correction(word))\n",
        "    else:\n",
        "      corrected_text.append(word)\n",
        "  return \" \".join(corrected_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MumecT8o2F4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['text']=train['text'].apply(lambda x: correct_spellings(x))\n",
        "test['text']=test['text'].apply(lambda x:correct_spellings(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1gr6Av14i4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmatizer=WordNetLemmatizer()\n",
        "stopwords=stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uP-fqwF2Tzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def corpus_creation(df):\n",
        "  corpus=[]\n",
        "  for tweet in tqdm(df['text']):\n",
        "    words = [lemmatizer.lemmatize(word.lower()) for word in tweet.split() if word not in stopwords]\n",
        "    corpus.append(words)\n",
        "  return corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Aw30a0n5pKr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0b55bde4-3b8b-4c9e-94cd-c3eccc50ca50"
      },
      "source": [
        "train_corpus = corpus_creation(train)\n",
        "test_corpus = corpus_creation(test)\n",
        "for tweet in test_corpus:\n",
        "  train_corpus.append(tweet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7613/7613 [00:02<00:00, 2985.87it/s]\n",
            "100%|██████████| 3263/3263 [00:00<00:00, 12721.94it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LMDh6Hs5QHC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "340e3806-cc01-4ad1-8dcb-3dd875b65873"
      },
      "source": [
        "nltk.download()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> wordnet\n",
            "    Downloading package wordnet to /root/nltk_data...\n",
            "      Unzipping corpora/wordnet.zip.\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZlwt2Tr5RA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings={}\n",
        "with open('/content/drive/My Drive/glove.6B.100d.txt','r') as f:\n",
        "  for line in f:\n",
        "    values=line.split()\n",
        "    word=values[0]\n",
        "    vectors=np.asarray(values[1:],dtype=np.float64)\n",
        "    embeddings[word]=vectors\n",
        "  f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht3C-baU68Sj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(oov_token='unk')\n",
        "tokenizer.fit_on_texts(train_corpus)\n",
        "sequences = tokenizer.texts_to_sequences(train_corpus)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=50, padding='pre', truncating='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-JLK01-Bj_w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c66a961f-7561-48ef-e9b4-57183abe6c80"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "num_words = len(word_index) +1\n",
        "embedding_matrix = np.zeros((num_words,100))\n",
        "for word, i in tqdm(word_index.items()):\n",
        "  if i>num_words:\n",
        "    continue\n",
        "  else:\n",
        "    emb_vec = embeddings.get(word)\n",
        "    if emb_vec is not None:\n",
        "      embedding_matrix[i]=emb_vec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 21152/21152 [00:00<00:00, 481359.46it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvIMXyD0NIfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.initializers import Constant"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NmfwfQnD265",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "ff855ef2-d41b-43fe-89c3-484d5e514c1b"
      },
      "source": [
        "model = Sequential()\n",
        "embedding=Embedding(input_dim=num_words, output_dim=100, embeddings_initializer=Constant(embedding_matrix), input_length=50, trainable = False)\n",
        "model.add(embedding)\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "lstm=LSTM(64, activation='tanh', recurrent_activation='tanh', use_bias=True)\n",
        "lstm_seq=LSTM(64, activation='tanh', recurrent_activation='tanh', use_bias=True, return_sequences=True)\n",
        "model.add(Bidirectional(lstm_seq, merge_mode='ave'))\n",
        "model.add(Bidirectional(lstm, merge_mode='ave'))\n",
        "model.add(Dense(1,activation=\"sigmoid\"))\n",
        "model.compile(optimizer=Adam(lr=1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 50, 100)           2115300   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 50, 100)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 50, 64)            84480     \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 64)                66048     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 2,265,893\n",
            "Trainable params: 150,593\n",
            "Non-trainable params: 2,115,300\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pzy0QrASSv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(padded_sequences[:train['target'].values.shape[0]],train['target'].values,test_size=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEa5zFC2TLiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history=model.fit(X_train,y_train,batch_size=4,epochs=8,validation_data=(X_test,y_test),verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w81V3C9ETgu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_sub=pd.read_csv('/content/drive/My Drive/sample_submission.csv')\n",
        "y_pre=model.predict(padded_sequences[train['target'].values.shape[0]:])\n",
        "y_pre=np.round(y_pre).astype(int).reshape(3263)\n",
        "sub=pd.DataFrame({'id':sample_sub['id'].values.tolist(),'target':y_pre})\n",
        "sub.to_csv('submission.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye_AL30fb_ju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}